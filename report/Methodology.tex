\chapter{Methodology}\label{methodology}%TODO: rewerite so all is design science adaptation?

While exploring the field in the previous chapter, the first research question was answered in the process.
The remaining chapters will be used to answer the remaining questions following an adaptation of the `design science' process.

%what is design science
As described in \cite{Vaishnavi2004}, design Science involves a five-step process consisting of the following phases: Awareness of the problem, suggestion, development, evaluation and conclusion.
These phases can be revisited during the process, resulting in an iterative cyclic process.
Repeating previous steps can often be necessary as more knowledge of a subject is acquired, and previous assumptions must be reconsidered.

While the report will generally follow this process, some of the steps are suited for adjustments to better fit the task.
Each of the steps are summarized below, with an explanation of the intended deviation from the normal process.

\section{Awareness}\label{methAware}

Gaining awareness of the problem is necessary to be able to solve it.
In this case, the problem will be any issues discovered with \gls{jive}.
Through a thorough exploration of \gls{jive} and its features, it is a fair assumption that some of the most apparent issues will be revealed.
This exploration is also intended to better understand whether \gls{jive} can be properly integrated with the teaching environment, or if any modifications are required.

While it is likely that several issues will be revealed, it is natural to continue the process of exploration instead of moving on to the next step in the design science process and repeating the entire cycle for each issue that is revealed.
This results in a focused exploration-phase, and likely a more efficient use of time.

\section{Suggestion}\label{methSuggest}

The same all-at-once approach will be taken when considering suggestions to solve the discovered issues.
During both this and the previous phase, it is necessary to prioritize the various issues according to the perceived importance and assumed effort of the issues.
This is mainly to provide focus for the next phase, development, where it is assumed that most of the time will be spent.
Proper prioritizing will help towards an efficient use of the available time. 

\section{Development}\label{methDevelop}

As opposed to the previous two steps, the attention is directed at single issues during the development-phase.
In this phase, it is expected that the awareness- and suggestion-phases will be revisited, triggered by the discovery of technical details that change the possibilities for a solution.
Partial implementations will be subject to internal evaluations where specific solutions are considered, and the awareness of the problem is updated accordingly.

\section{Evaluation}\label{methEval}

While each of the issues that result in an implemented change goes through internal evaluation during development, there is also need for external evaluation.
This is another phase where it is suitable to gather all issues, as they are all part of the package that is \gls{jive}.

In order to determine the usefulness of \gls{jive}, and the effect of the implemented changes, the external evaluation will be performed with participants from the targeted user group.
As mentioned in the introduction, this group consists of students in their second year of the computer science and informatics programs.

The types of evaluations available are limited, with web-based questionnaires and in-person interviews being most suitable.

%web-based q
Reaching a wide audience, the use of web-based questionnaires can provide a large amount of data to support the research, but the nature of what is being evaluated makes this method unfit.
In order to give proper answers, the participants require a hands-on experience with the tool, and that would require them to acquire and install both the original version, and the modified version
This is a rather large obstacle that would deter most potential candidates from participating, and defeats the point of a questionnaire.
Although they could be tasked with comparing images of existing and new functionality, and given performance numbers to consider, it would not be the same as actually experiencing the differences, and getting to explore them at the users own pace.

Another issue appears in how questions are formulated, and what kind of answers they result in.
Requiring participants to quantify their experiences along numbered scales makes it easy to combine the results from all participants.
On the other hand, as each question must be limited in scope in order to get a precise answer, the amount of questions needed to get a good overview of each participants experience, can easily be perceived as different ways of asking the same question, resulting in repeated answers.

%interview
The alternative is an in-person evaluation with a smaller group of students, where the participants get access to a pre-configured system and enough time to make an informed opinion of what they are presented with.
As the availability of volunteers is limited, a properly executed in-person evaluation is likely to get more information out of the participants, by asking questions and discussing potential issues with them.

A hybrid approach could also be used by performing an in-person evaluation, and requiring participants to fill in a questionnaire afterwards.
This would still require one or more pre-configured systems, and some time spent on each participant to give an introduction to the tool they are evaluating.
Doing this in an effective manner, requires multiple assistants, and while the meaning of the questions could be further explained upon request, the answers would still be limited in the same manner as with a web-based questionnaire.

\section{Conclusion}\label{methConclude}

The final phase will summarize the results from the previous steps in light of the research questions, and attempt to reach a conclusion on the research.










